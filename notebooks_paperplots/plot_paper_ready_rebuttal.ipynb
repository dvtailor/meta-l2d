{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43954f7f-08c1-40a6-b913-d0603297bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8eeb65f-7946-45a3-b589-ddea372d834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e56c25-55f3-4fe8-8131-bead1b8691a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"font.family\"] = 'cmu serif'\n",
    "\n",
    "page_width = 6.75 # aistats width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2de9516-784f-480c-859b-0df3176958d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'cifar10'\n",
    "results_path = f'../runs_final/{ds_name}/softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5a820a6-efbd-478d-a8ee-19bdaedc5e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_lst = [1071,3918,4420,5251,6637]\n",
    "metrics_lst = ['cov', 'sys_acc', 'exp_acc', 'clf_acc', 'exp_acc_alone', 'clf_acc_alone', 'val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71eac61a-1414-44ed-8ae9-0f93ae2caabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2d_type_lst = ['pop_rebuttal']\n",
    "p_out_lst = [0.1]\n",
    "p_cntx_inclusion_lst = [0.,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d975ee-28f6-4b08-b739-ee5861a12756",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for l2d_type in l2d_type_lst:\n",
    "    results[l2d_type] = {}\n",
    "    \n",
    "    if l2d_type != 'single':\n",
    "        for p_cntx_inclusion in p_cntx_inclusion_lst:\n",
    "            results[l2d_type][p_cntx_inclusion] = {}\n",
    "\n",
    "            metrics_all = {metric:[[] for _ in range(len(p_out_lst))] for metric in metrics_lst}\n",
    "\n",
    "            for ii,p_out in enumerate(p_out_lst):\n",
    "                for seed in seed_lst:\n",
    "                    fn_path = os.path.join(results_path, f'l2d_{l2d_type}', f'p{p_out}_seed{seed}', f'eval1.0_pc{p_cntx_inclusion}.log')\n",
    "\n",
    "                    try:\n",
    "                        line = open(fn_path).readline().rstrip()\n",
    "                    except FileNotFoundError:\n",
    "                        print(fn_path)\n",
    "                    else:\n",
    "                        line_split_grp = [line.split()[i:i+2] for i in range(0, len(line.split()),2)]\n",
    "                        for [metric,val] in line_split_grp:\n",
    "                            if metric=='cov':\n",
    "                                cov = val.split('/')\n",
    "                                metrics_all[metric][ii].append(100*int(cov[0])/int(cov[1]))\n",
    "                            else:\n",
    "                                metrics_all[metric][ii].append(float(val))\n",
    "\n",
    "            for metric, vals in metrics_all.items():\n",
    "                results[l2d_type][p_cntx_inclusion][metric] = np.vstack(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "897065a0-da62-4c96-b6f4-66dd9f04e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2d_type = 'single'\n",
    "results[l2d_type] = {}\n",
    "results[l2d_type][None] = {}\n",
    "\n",
    "metrics_all = {metric:[[] for _ in range(len(p_out_lst))] for metric in metrics_lst}\n",
    "\n",
    "for ii,p_out in enumerate(p_out_lst):\n",
    "    for seed in seed_lst:\n",
    "        fn_path = os.path.join(results_path, f'l2d_{l2d_type}', f'p{p_out}_seed{seed}', f'eval1.0.log')\n",
    "\n",
    "        try:\n",
    "            line = open(fn_path).readline().rstrip()\n",
    "        except FileNotFoundError:\n",
    "            print(fn_path)\n",
    "        else:\n",
    "            line_split_grp = [line.split()[i:i+2] for i in range(0, len(line.split()),2)]\n",
    "            for [metric,val] in line_split_grp:\n",
    "                if metric=='cov':\n",
    "                    cov = val.split('/')\n",
    "                    metrics_all[metric][ii].append(100*int(cov[0])/int(cov[1]))\n",
    "                else:\n",
    "                    metrics_all[metric][ii].append(float(val))\n",
    "\n",
    "for metric, vals in metrics_all.items():\n",
    "    results[l2d_type][None][metric] = np.vstack(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a75f2be-3dbd-4aff-a706-5e0b89e49e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pretrained classifier\n",
    "pretrained_results_path = f'../pretrained/{ds_name}'\n",
    "l2d_type = 'pretrained'\n",
    "results[l2d_type] = {}\n",
    "results[l2d_type][None] = {}\n",
    "\n",
    "pretrained_metrics_lst = ['clf_acc','val_loss']\n",
    "metrics_all = {metric:[] for metric in pretrained_metrics_lst}\n",
    "\n",
    "for seed in seed_lst:\n",
    "    fn_path = os.path.join(pretrained_results_path, f'seed{seed}', f'eval.log')\n",
    "\n",
    "    try:\n",
    "        line = open(fn_path).readline().rstrip()\n",
    "    except FileNotFoundError:\n",
    "        print(fn_path)\n",
    "    else:\n",
    "        line_split_grp = [line.split()[i:i+2] for i in range(0, len(line.split()),2)]\n",
    "        for [metric,val] in line_split_grp:\n",
    "            if metric=='cov':\n",
    "                cov = val.split('/')\n",
    "                metrics_all[metric].append(int(cov[0])/int(cov[1]))\n",
    "            else:\n",
    "                metrics_all[metric].append(float(val))\n",
    "                \n",
    "for metric, vals in metrics_all.items():\n",
    "    results[l2d_type][None][metric] = np.vstack(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1269c244-5027-4b78-a3f1-fc9adcab7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_red = mpl.colormaps['Set1'](0)\n",
    "c_blue = mpl.colormaps['Set1'](1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203128f3-d538-4d60-b7a2-5b5e8be478ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_text = {\n",
    "    'cov':'Coverage (\\%)',\n",
    "    'sys_acc': 'System accuracy (\\%)',\n",
    "    'exp_acc': 'Expert accuracy\\non deferred examples (\\%)',\n",
    "    'clf_acc': 'Classifier accuracy\\n on non-deferred examples (\\%)',\n",
    "    'clf_acc_alone': 'Classifier accuracy\\n on all examples (\\%)',\n",
    "    'val_loss': 'Test loss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb1843bc-819e-4bae-89da-ec0545469f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2d_type_to_text = {\n",
    "    'single': 'single-L2D',\n",
    "    'pop': 'L2D-Pop (NP)',\n",
    "    # 'pop_attn': 'Population w/ attention'\n",
    "    'pop_attn': 'Population + Attn',\n",
    "    'single_finetune': 'Single-expert (finetune)',\n",
    "    'pretrained': 'non-L2D classifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c9795d9-50df-4add-8de3-0215e8895aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_yticks_cov = {\n",
    "    'cifar10' : np.arange(93,100,2), #np.arange(92,101,2),\n",
    "}\n",
    "\n",
    "dataset_to_yticks_sysacc = {\n",
    "    'cifar10' : np.arange(87,91,1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730e37b-17b0-4bf5-9bfe-882e4297b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(3.,1.6), constrained_layout=True)\n",
    "\n",
    "p_cntxt_show = [0,0.2,0.4,0.6,0.8,1.0]\n",
    "\n",
    "metric_to_col = {'single':c_red,'pop':c_blue, 'pretrained':'g'}\n",
    "metric_to_marker = {'single':'s-','pop':'o-'}\n",
    "errbar_args={'capsize':2, 'markersize':4, 'elinewidth':1, 'capthick':1, 'lw':1.5} # 'fmt':'o-'\n",
    "\n",
    "fs_ax_lbl=7\n",
    "fs_ax_ticks = 7\n",
    "fs_ax_title = 8\n",
    "\n",
    "l2d_type = 'pop'\n",
    "for ax,metric in zip(axs,['cov', 'exp_acc']):\n",
    "    res_all = np.vstack([results['pop_rebuttal'][pp][metric] for pp in p_cntxt_show])\n",
    "    metric_mean = np.mean(res_all, axis=1)\n",
    "    metric_std = np.std(res_all, axis=1)\n",
    "    \n",
    "    ax.errorbar(np.array(p_cntxt_show), metric_mean, yerr=metric_std, label=l2d_type_to_text[l2d_type], \\\n",
    "                c=metric_to_col[l2d_type], fmt=metric_to_marker[l2d_type], **errbar_args)\n",
    "    \n",
    "    res_single = results['single'][None][metric]\n",
    "    res_single_mean = np.mean(res_single)\n",
    "    res_single_std = np.std(res_single)\n",
    "    ax.plot(np.array(p_cntxt_show), [res_single_mean]*len(p_cntxt_show), color=metric_to_col['single'], ls='--', label=l2d_type_to_text['single'])\n",
    "    ax.fill_between(np.array(p_cntxt_show), [(res_single_mean-res_single_std)]*len(p_cntxt_show), \\\n",
    "                    [(res_single_mean+res_single_std)]*len(p_cntxt_show), alpha=0.1, color=metric_to_col['single'])\n",
    "    \n",
    "    ax.set_xlabel('Probability of observing' + '\\n' +  'context set ($p$)', fontsize=fs_ax_lbl)\n",
    "    ax.set_ylabel(metrics_to_text[metric], fontsize=fs_ax_lbl)\n",
    "    ax.grid(True, alpha=0.15)\n",
    "    ax.set_xticks([0,0.5,1])\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(direction='in', labelsize=fs_ax_ticks,length=2., width=0.75)\n",
    "    [x.set_linewidth(.5) for x in ax.spines.values()]\n",
    "    \n",
    "# # show non-L2D classifier performance\n",
    "# res_pretrained = results['pretrained'][None]['clf_acc']\n",
    "# res_pretrained_mean = np.mean(res_pretrained)\n",
    "# res_pretrained_std = np.std(res_pretrained)\n",
    "# axs[1].plot(np.array(p_cntxt_show), [res_pretrained_mean]*len(p_cntxt_show), color=metric_to_col['pretrained'], ls='--', label=l2d_type_to_text['pretrained'])\n",
    "# axs[1].fill_between(np.array(p_cntxt_show), [(res_pretrained_mean-res_pretrained_std)]*len(p_cntxt_show), \\\n",
    "#                     [(res_pretrained_mean+res_pretrained_std)]*len(p_cntxt_show), alpha=0.1, color=metric_to_col['pretrained'])\n",
    "    \n",
    "# manual setting of yticks\n",
    "axs[0].set_yticks(dataset_to_yticks_cov[ds_name]);\n",
    "# axs[1].set_yticks(dataset_to_yticks_sysacc[ds_name]);\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "order = [1,0] #[2,0,1]\n",
    "leg = fig.legend([handles[idx] for idx in order],[labels[idx] for idx in order], \\\n",
    "                 fontsize=fs_ax_title,frameon=False,ncol=3,loc='upper center',bbox_to_anchor=(0.5, 1.15))\n",
    "leg.get_frame().set_linewidth(0.5)\n",
    "\n",
    "# fig.savefig(f'context_dropping_testtime.pdf', dpi=600, facecolor='white', bbox_inches='tight', pad_inches=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
